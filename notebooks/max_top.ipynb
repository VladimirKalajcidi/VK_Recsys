{"metadata":{"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9766180,"sourceType":"datasetVersion","datasetId":5981185}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\nimport xgboost as xgb","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T17:50:13.970153Z","iopub.execute_input":"2024-11-01T17:50:13.971534Z","iopub.status.idle":"2024-11-01T17:50:17.239443Z","shell.execute_reply.started":"2024-11-01T17:50:13.971461Z","shell.execute_reply":"2024-11-01T17:50:17.238191Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/input/vk-recsys","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T17:59:58.465168Z","iopub.execute_input":"2024-11-01T17:59:58.465678Z","iopub.status.idle":"2024-11-01T17:59:58.474277Z","shell.execute_reply.started":"2024-11-01T17:59:58.465635Z","shell.execute_reply":"2024-11-01T17:59:58.473071Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/vk-recsys\n","output_type":"stream"}]},{"cell_type":"code","source":"train_interactions = pd.read_parquet('train_interactions.parquet')\ntrain_interactions = train_interactions.sort_values('user_id').reset_index(drop=True)\n\nusers_meta = pd.read_parquet('users_meta.parquet')\nitems_meta = pd.read_parquet('items_meta.parquet')","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T17:59:58.476448Z","iopub.execute_input":"2024-11-01T17:59:58.477323Z","iopub.status.idle":"2024-11-01T18:01:09.379178Z","shell.execute_reply.started":"2024-11-01T17:59:58.477266Z","shell.execute_reply":"2024-11-01T18:01:09.377700Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"items_meta=items_meta.drop(columns=['embeddings'])","metadata":{"execution":{"iopub.status.busy":"2024-11-01T18:01:09.380844Z","iopub.execute_input":"2024-11-01T18:01:09.381230Z","iopub.status.idle":"2024-11-01T18:01:09.435569Z","shell.execute_reply.started":"2024-11-01T18:01:09.381192Z","shell.execute_reply":"2024-11-01T18:01:09.434259Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def calculate_unique_sources(df):\n    \"\"\" Calculates the number of unique source_ids for each user_id in the given DataFrame. \"\"\"\n    user_sources = df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n    unique_source_count = user_sources.groupby('user_id')['source_id'].nunique().reset_index(name='unique_source_count')\n    return unique_source_count","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T18:01:09.437111Z","iopub.execute_input":"2024-11-01T18:01:09.437585Z","iopub.status.idle":"2024-11-01T18:01:09.444217Z","shell.execute_reply.started":"2024-11-01T18:01:09.437535Z","shell.execute_reply":"2024-11-01T18:01:09.442929Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n\n\n# Prepare DataFrames for storing item metrics and user metrics\nitem_metrics_final = pd.DataFrame()\nuser_metrics_final = pd.DataFrame()\n\n# Define functions for metrics calculations\ndef calculate_item_metrics(df):\n    item_metrics = df.groupby('item_id').agg(\n        total_likes=('like', 'sum'),\n        total_dislikes=('dislike', 'sum'),\n        total_shares=('share', 'sum'),\n        total_bookmarks=('bookmarks', 'sum'),\n        avg_timespent=('timespent', 'mean'),\n    ).reset_index()\n    return item_metrics\n\ndef calculate_gender_metrics(df, users_meta):\n    # Merge interactions with user metadata\n    extended_df = df.merge(users_meta, on='user_id', how='left')\n\n    # Calculate likes and dislikes for males (1) and females (2)\n    gender_likes = extended_df[extended_df['like'] == 1].groupby(['item_id', 'gender']).size().unstack(fill_value=0)\n\n    male_likes = gender_likes.get(1, pd.Series(0)).reset_index(name='male_likes')\n    female_likes = gender_likes.get(2, pd.Series(0)).reset_index(name='female_likes')\n\n    gender_dislikes = extended_df[extended_df['dislike'] == 1].groupby(['item_id', 'gender']).size().unstack(fill_value=0)\n\n    male_dislikes = gender_dislikes.get(1, pd.Series(0)).reset_index(name='male_dislikes')\n    female_dislikes = gender_dislikes.get(2, pd.Series(0)).reset_index(name='female_dislikes')\n\n    # Merge the results\n    male_likes = male_likes.rename(columns={male_likes.columns[0]: 'item_id'})\n    female_likes = female_likes.rename(columns={female_likes.columns[0]: 'item_id'})\n    male_dislikes = male_dislikes.rename(columns={male_dislikes.columns[0]: 'item_id'})\n    female_dislikes = female_dislikes.rename(columns={female_dislikes.columns[0]: 'item_id'})\n\n    return male_likes, female_likes, male_dislikes, female_dislikes\n\ndef calculate_unique_sources(df):\n    user_sources = df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n    unique_source_count = user_sources.groupby('user_id')['source_id'].nunique().reset_index(name='unique_source_count')\n    return unique_source_count\n","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T18:01:09.446136Z","iopub.execute_input":"2024-11-01T18:01:09.446591Z","iopub.status.idle":"2024-11-01T18:01:09.464553Z","shell.execute_reply.started":"2024-11-01T18:01:09.446528Z","shell.execute_reply":"2024-11-01T18:01:09.463455Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef create_source_matrix(train_interactions, users_meta, items_meta):\n    extended_df = train_interactions.merge(users_meta, on='user_id', how='left')\n\n    # Step 2: Merge with items_meta to get source_id\n    extended_df = extended_df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n\n    # Step 3: Calculate total likes and encounters by source_id\n    likes_count = extended_df[extended_df['like'] == 1] \\\n        .groupby('source_id')['item_id'] \\\n        .count() \\\n        .reset_index(name='total_likes_all_video')\n    dislikes_count = extended_df[extended_df['dislike'] == 1] \\\n        .groupby('source_id')['item_id'] \\\n        .count() \\\n        .reset_index(name='total_dislikes_all_video')\n\n    encounters_count = extended_df \\\n        .groupby('source_id')['item_id'] \\\n        .count() \\\n        .reset_index(name='total_encounters_all_video')\n\n    # Step 4: Calculate gender sums who liked each source's items\n    gender_sum = extended_df[extended_df['like'] == 1] \\\n        .groupby('source_id')['gender'] \\\n        .sum() \\\n        .reset_index(name='liked_gender_sum_all_video')\n\n    # Step 5: Merge all metrics into a final DataFrame\n    result_matrix = likes_count \\\n        .merge(dislikes_count, on='source_id', how='outer') \\\n        .merge(encounters_count, on='source_id', how='outer') \\\n        .merge(gender_sum, on='source_id', how='outer')\n\n    # Step 6: Calculate the gender ratio\n    result_matrix['gender_ratio'] = result_matrix['liked_gender_sum_all_video'].fillna(0) / result_matrix['total_likes_all_video'].replace(0, pd.NA)\n\n    # Fill NaN values for likes and encounters\n    result_matrix.fillna({'total_likes_all_video': 0, 'total_encounters_all_video': 0, 'liked_gender_sum_all_video': 0}, inplace=True)\n    result_matrix=result_matrix.drop(columns=['liked_gender_sum_all_video'])\n    return result_matrix\n\n# Example of calling the function\n# result = create_source_matrix(\"path/to/train_interactions.parquet\", \"path/to/users_meta.parquet\", \"path/to/items_meta.parquet\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T18:01:09.468787Z","iopub.execute_input":"2024-11-01T18:01:09.469368Z","iopub.status.idle":"2024-11-01T18:01:09.483644Z","shell.execute_reply.started":"2024-11-01T18:01:09.469315Z","shell.execute_reply":"2024-11-01T18:01:09.482377Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Call the function to calculate metrics and merge with items_meta\nresult = create_source_matrix(train_interactions, users_meta, items_meta)\nresult.fillna(0, inplace=True)\n# Display the result DataFrame (or save it)\nprint(result)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T18:01:09.485238Z","iopub.execute_input":"2024-11-01T18:01:09.485610Z","iopub.status.idle":"2024-11-01T18:01:43.785452Z","shell.execute_reply.started":"2024-11-01T18:01:09.485571Z","shell.execute_reply":"2024-11-01T18:01:43.784325Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"       source_id  total_likes_all_video  total_dislikes_all_video  \\\n0              0                    9.0                       3.0   \n1              1                    7.0                       0.0   \n2              2                    1.0                       0.0   \n3              3                   14.0                       0.0   \n4              4                   21.0                       0.0   \n...          ...                    ...                       ...   \n19608      19608                    6.0                       0.0   \n19609      19609                    7.0                       0.0   \n19610      19610                  200.0                       6.0   \n19611      19611                 1337.0                      18.0   \n19612      19612                  217.0                       0.0   \n\n       total_encounters_all_video  gender_ratio  \n0                            2063      1.333333  \n1                             178      1.000000  \n2                              46      1.000000  \n3                            4793      1.000000  \n4                            1565      1.952381  \n...                           ...           ...  \n19608                          78      1.833333  \n19609                          32      1.571429  \n19610                        3817      1.315000  \n19611                       37959      1.485415  \n19612                        1667      1.958525  \n\n[19613 rows x 5 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming item_metrics, result, and items_meta are already defined DataFrames.\n\ndef merge_item_metrics_with_result(item_metrics, result, items_meta):\n    # Step 1: Merge item_metrics with items_meta to get source_id\n    merged_df = item_metrics.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n    \n    # Step 2: Merge the result DataFrame with the merged DataFrame on source_id\n    final_df = merged_df.merge(result, on='source_id', how='left')\n    \n    return final_df\n\n# Example usage:\n# item_metrics = pd.DataFrame(...)  # Your item metrics DataFrame\n# result = pd.DataFrame(...)         # Your result DataFrame\n# items_meta = pd.DataFrame(...)     # Your items_meta DataFrame\n\n# final_merged_result = merge_item_metrics_with_result(item_metrics, result, items_meta)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:51:54.529225Z","iopub.execute_input":"2024-11-01T17:51:54.529657Z","iopub.status.idle":"2024-11-01T17:51:54.536578Z","shell.execute_reply.started":"2024-11-01T17:51:54.529605Z","shell.execute_reply":"2024-11-01T17:51:54.535085Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Loop through each specified row count\n# Calculate item metrics\nitem_metrics = calculate_item_metrics(train_interactions)\nmale_likes, female_likes, male_dislikes, female_dislikes = calculate_gender_metrics(train_interactions, users_meta)\n\n# Merge gender metrics\nitem_metrics = item_metrics.merge(male_likes, on='item_id', how='left')\nitem_metrics = item_metrics.merge(female_likes, on='item_id', how='left')\nitem_metrics = item_metrics.merge(male_dislikes, on='item_id', how='left')\nitem_metrics = item_metrics.merge(female_dislikes, on='item_id', how='left')\nitem_metrics = item_metrics.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\nitem_metrics = item_metrics.merge(result, on='source_id', how='left')\nitem_metrics = item_metrics.drop(columns=['source_id'])\n# Add suffix to distinguish metrics by row count\n\nitem_metrics.columns = [f'{col}_all' if col != 'item_id' else 'item_id' for col in item_metrics.columns]\n\n# Merge into the final aggregated metrics DataFrame\nif item_metrics_final.empty:\n    item_metrics_final = item_metrics\nelse:\n    item_metrics_final = item_metrics_final.merge(item_metrics, on='item_id', how='outer')\n\n# Calculate unique source counts for users and merge into user metrics DataFrame\nuser_unique_sources = calculate_unique_sources(train_interactions)\n\n# Add suffix for user metrics by row count\nuser_unique_sources.columns = ['user_id', f'unique_source_count_all']\n\nif user_metrics_final.empty:\n    user_metrics_final = user_unique_sources\nelse:\n    user_metrics_final = user_metrics_final.merge(user_unique_sources, on='user_id', how='outer')\n","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T18:01:43.786870Z","iopub.execute_input":"2024-11-01T18:01:43.787438Z","iopub.status.idle":"2024-11-01T18:03:30.025049Z","shell.execute_reply.started":"2024-11-01T18:01:43.787395Z","shell.execute_reply":"2024-11-01T18:03:30.023867Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"items_meta = items_meta.merge(item_metrics_final, on='item_id', how='left')\nitems_meta.fillna(0, inplace=True)\n\nusers_meta = users_meta.merge(user_metrics_final, on='user_id', how='left')\nusers_meta.fillna(0, inplace=True)","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T18:03:30.026752Z","iopub.execute_input":"2024-11-01T18:03:30.027165Z","iopub.status.idle":"2024-11-01T18:03:30.115933Z","shell.execute_reply.started":"2024-11-01T18:03:30.027124Z","shell.execute_reply":"2024-11-01T18:03:30.114725Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_pairs = pd.read_csv('test_pairs.csv')\n\nusers = test_pairs['user_id'].unique()\nitems = test_pairs['item_id'].unique()","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T18:03:30.117470Z","iopub.execute_input":"2024-11-01T18:03:30.117969Z","iopub.status.idle":"2024-11-01T18:03:30.860726Z","shell.execute_reply.started":"2024-11-01T18:03:30.117909Z","shell.execute_reply":"2024-11-01T18:03:30.859734Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_interactions['like'] = train_interactions['like'].astype('int32')    # Convert to signed integer\ntrain_interactions['dislike'] = train_interactions['dislike'].astype('int32')  # Convert to signed integer\n\ntrain_interactions['label'] = abs(train_interactions['like'] - train_interactions['dislike'])\n\n#train_interactions = train_interactions[train_interactions['user_id'].isin(users)][train_interactions['item_id'].isin(items)]\ntrain_interactions = train_interactions.loc[5_000_000:]","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T18:03:30.862193Z","iopub.execute_input":"2024-11-01T18:03:30.862641Z","iopub.status.idle":"2024-11-01T18:03:32.119197Z","shell.execute_reply.started":"2024-11-01T18:03:30.862573Z","shell.execute_reply":"2024-11-01T18:03:32.118219Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_interactions = train_interactions.merge(users_meta, on='user_id', how='left')\ntrain_interactions = train_interactions.merge(items_meta, on='item_id', how='left')","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T18:03:32.120665Z","iopub.execute_input":"2024-11-01T18:03:32.121163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_interactions.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_interactions = train_interactions[['gender', 'age', 'unique_source_count_all',\n       'source_id', 'duration', 'total_likes_x_all', 'total_dislikes_all',\n       'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n       'male_likes_x_all', 'female_likes_x_all', 'male_dislikes_all',\n       'female_dislikes_all', 'total_likes_y_all', 'item_encounter_count_all',\n       'male_likes_y_all', 'female_likes_y_all', 'avg_likes_per_gender_all', 'label']]","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T13:32:13.138107Z","iopub.execute_input":"2024-11-01T13:32:13.138628Z","iopub.status.idle":"2024-11-01T13:32:20.771447Z","shell.execute_reply.started":"2024-11-01T13:32:13.138570Z","shell.execute_reply":"2024-11-01T13:32:20.769994Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"params = {\n    'tree_method': 'exact',\n    'objective': 'binary:logistic'\n}\nnum_boost_round = 5\n\nclf = xgb.XGBClassifier(n_estimators=num_boost_round, scale_pos_weight=11.839, **params)\nclf.fit(train_interactions.drop(columns=['label']), train_interactions['label'], \n        verbose=10)","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-11-01T13:32:20.773726Z","iopub.execute_input":"2024-11-01T13:32:20.774388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pairs = pd.read_csv('data/test_pairs.csv')\n\ntest_pairs = test_pairs.merge(users_meta, on='user_id', how='left')\ntest_pairs = test_pairs.merge(items_meta, on='item_id', how='left')\n\ntest_pairs = test_pairs[['gender', 'age', 'unique_source_count_all', 'source_id', 'duration', 'total_likes_all', 'total_dislikes_all',\n                            'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n                            'male_likes_all', 'female_likes_all', 'male_dislikes_all',\n                            'female_dislikes_all']]","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = clf.predict_proba(test_pairs)\nresult = [i[1] for i in result]\n\ntest_pairs = pd.read_csv('data/test_pairs.csv')\ntest_pairs['predict'] = result\n\ntest_pairs.to_csv('sub_lightgbm.csv', index=False)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"execution_count":null,"outputs":[]}]}