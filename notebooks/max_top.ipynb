{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:50:13.971534Z",
     "iopub.status.busy": "2024-11-01T17:50:13.970153Z",
     "iopub.status.idle": "2024-11-01T17:50:17.239443Z",
     "shell.execute_reply": "2024-11-01T17:50:17.238191Z",
     "shell.execute_reply.started": "2024-11-01T17:50:13.971461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:59:58.465678Z",
     "iopub.status.busy": "2024-11-01T17:59:58.465168Z",
     "iopub.status.idle": "2024-11-01T17:59:58.474277Z",
     "shell.execute_reply": "2024-11-01T17:59:58.473071Z",
     "shell.execute_reply.started": "2024-11-01T17:59:58.465635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vladimirkalajcidi/vk_recsys\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/vladimirkalajcidi/vk_recsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:59:58.477323Z",
     "iopub.status.busy": "2024-11-01T17:59:58.476448Z",
     "iopub.status.idle": "2024-11-01T18:01:09.379178Z",
     "shell.execute_reply": "2024-11-01T18:01:09.377700Z",
     "shell.execute_reply.started": "2024-11-01T17:59:58.477266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_interactions = pd.read_parquet('data/train_interactions.parquet')\n",
    "train_interactions = train_interactions.sort_values('user_id').reset_index(drop=True)\n",
    "\n",
    "users_meta = pd.read_parquet('data/users_meta.parquet')\n",
    "items_meta = pd.read_parquet('data/items_meta.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:01:09.381230Z",
     "iopub.status.busy": "2024-11-01T18:01:09.380844Z",
     "iopub.status.idle": "2024-11-01T18:01:09.435569Z",
     "shell.execute_reply": "2024-11-01T18:01:09.434259Z",
     "shell.execute_reply.started": "2024-11-01T18:01:09.381192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "items_meta=items_meta.drop(columns=['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:01:09.437585Z",
     "iopub.status.busy": "2024-11-01T18:01:09.437111Z",
     "iopub.status.idle": "2024-11-01T18:01:09.444217Z",
     "shell.execute_reply": "2024-11-01T18:01:09.442929Z",
     "shell.execute_reply.started": "2024-11-01T18:01:09.437535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_unique_sources(df):\n",
    "    \"\"\" Calculates the number of unique source_ids for each user_id in the given DataFrame. \"\"\"\n",
    "    user_sources = df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "    unique_source_count = user_sources.groupby('user_id')['source_id'].nunique().reset_index(name='unique_source_count')\n",
    "    return unique_source_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:01:09.446591Z",
     "iopub.status.busy": "2024-11-01T18:01:09.446136Z",
     "iopub.status.idle": "2024-11-01T18:01:09.464553Z",
     "shell.execute_reply": "2024-11-01T18:01:09.463455Z",
     "shell.execute_reply.started": "2024-11-01T18:01:09.446528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Prepare DataFrames for storing item metrics and user metrics\n",
    "item_metrics_final = pd.DataFrame()\n",
    "user_metrics_final = pd.DataFrame()\n",
    "\n",
    "# Define functions for metrics calculations\n",
    "def calculate_item_metrics(df):\n",
    "    item_metrics = df.groupby('item_id').agg(\n",
    "        total_likes=('like', 'sum'),\n",
    "        total_dislikes=('dislike', 'sum'),\n",
    "        total_shares=('share', 'sum'),\n",
    "        total_bookmarks=('bookmarks', 'sum'),\n",
    "        avg_timespent=('timespent', 'mean'),\n",
    "    ).reset_index()\n",
    "    return item_metrics\n",
    "\n",
    "def calculate_gender_metrics(df, users_meta):\n",
    "    # Merge interactions with user metadata\n",
    "    extended_df = df.merge(users_meta, on='user_id', how='left')\n",
    "\n",
    "    # Calculate likes and dislikes for males (1) and females (2)\n",
    "    gender_likes = extended_df[extended_df['like'] == 1].groupby(['item_id', 'gender']).size().unstack(fill_value=0)\n",
    "\n",
    "    male_likes = gender_likes.get(1, pd.Series(0)).reset_index(name='male_likes')\n",
    "    female_likes = gender_likes.get(2, pd.Series(0)).reset_index(name='female_likes')\n",
    "\n",
    "    gender_dislikes = extended_df[extended_df['dislike'] == 1].groupby(['item_id', 'gender']).size().unstack(fill_value=0)\n",
    "\n",
    "    male_dislikes = gender_dislikes.get(1, pd.Series(0)).reset_index(name='male_dislikes')\n",
    "    female_dislikes = gender_dislikes.get(2, pd.Series(0)).reset_index(name='female_dislikes')\n",
    "\n",
    "    # Merge the results\n",
    "    male_likes = male_likes.rename(columns={male_likes.columns[0]: 'item_id'})\n",
    "    female_likes = female_likes.rename(columns={female_likes.columns[0]: 'item_id'})\n",
    "    male_dislikes = male_dislikes.rename(columns={male_dislikes.columns[0]: 'item_id'})\n",
    "    female_dislikes = female_dislikes.rename(columns={female_dislikes.columns[0]: 'item_id'})\n",
    "\n",
    "    return male_likes, female_likes, male_dislikes, female_dislikes\n",
    "\n",
    "def calculate_unique_sources(df):\n",
    "    user_sources = df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "    unique_source_count = user_sources.groupby('user_id')['source_id'].nunique().reset_index(name='unique_source_count')\n",
    "    return unique_source_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:01:09.469368Z",
     "iopub.status.busy": "2024-11-01T18:01:09.468787Z",
     "iopub.status.idle": "2024-11-01T18:01:09.483644Z",
     "shell.execute_reply": "2024-11-01T18:01:09.482377Z",
     "shell.execute_reply.started": "2024-11-01T18:01:09.469315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_source_matrix(train_interactions, users_meta, items_meta):\n",
    "    extended_df = train_interactions.merge(users_meta, on='user_id', how='left')\n",
    "\n",
    "    # Step 2: Merge with items_meta to get source_id\n",
    "    extended_df = extended_df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "\n",
    "    # Step 3: Calculate total likes and encounters by source_id\n",
    "    likes_count = extended_df[extended_df['like'] == 1] \\\n",
    "        .groupby('source_id')['item_id'] \\\n",
    "        .count() \\\n",
    "        .reset_index(name='total_likes_all_video')\n",
    "    dislikes_count = extended_df[extended_df['dislike'] == 1] \\\n",
    "        .groupby('source_id')['item_id'] \\\n",
    "        .count() \\\n",
    "        .reset_index(name='total_dislikes_all_video')\n",
    "\n",
    "    encounters_count = extended_df \\\n",
    "        .groupby('source_id')['item_id'] \\\n",
    "        .count() \\\n",
    "        .reset_index(name='total_encounters_all_video')\n",
    "\n",
    "    # Step 4: Calculate gender sums who liked each source's items\n",
    "    gender_sum = extended_df[extended_df['like'] == 1] \\\n",
    "        .groupby('source_id')['gender'] \\\n",
    "        .sum() \\\n",
    "        .reset_index(name='liked_gender_sum_all_video')\n",
    "\n",
    "    # Step 5: Merge all metrics into a final DataFrame\n",
    "    result_matrix = likes_count \\\n",
    "        .merge(dislikes_count, on='source_id', how='outer') \\\n",
    "        .merge(encounters_count, on='source_id', how='outer') \\\n",
    "        .merge(gender_sum, on='source_id', how='outer')\n",
    "\n",
    "    # Step 6: Calculate the gender ratio\n",
    "    result_matrix['gender_ratio'] = result_matrix['liked_gender_sum_all_video'].fillna(0) / result_matrix['total_likes_all_video'].replace(0, pd.NA)\n",
    "\n",
    "    # Fill NaN values for likes and encounters\n",
    "    result_matrix.fillna({'total_likes_all_video': 0, 'total_encounters_all_video': 0, 'liked_gender_sum_all_video': 0}, inplace=True)\n",
    "    result_matrix=result_matrix.drop(columns=['liked_gender_sum_all_video'])\n",
    "    return result_matrix\n",
    "\n",
    "# Example of calling the function\n",
    "# result = create_source_matrix(\"path/to/train_interactions.parquet\", \"path/to/users_meta.parquet\", \"path/to/items_meta.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:01:09.485610Z",
     "iopub.status.busy": "2024-11-01T18:01:09.485238Z",
     "iopub.status.idle": "2024-11-01T18:01:43.785452Z",
     "shell.execute_reply": "2024-11-01T18:01:43.784325Z",
     "shell.execute_reply.started": "2024-11-01T18:01:09.485571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       source_id  total_likes_all_video  total_dislikes_all_video  \\\n",
      "0              0                    9.0                       3.0   \n",
      "1              1                    7.0                       0.0   \n",
      "2              2                    1.0                       0.0   \n",
      "3              3                   14.0                       0.0   \n",
      "4              4                   21.0                       0.0   \n",
      "...          ...                    ...                       ...   \n",
      "19608      19608                    6.0                       0.0   \n",
      "19609      19609                    7.0                       0.0   \n",
      "19610      19610                  200.0                       6.0   \n",
      "19611      19611                 1337.0                      18.0   \n",
      "19612      19612                  217.0                       0.0   \n",
      "\n",
      "       total_encounters_all_video  gender_ratio  \n",
      "0                            2063      1.333333  \n",
      "1                             178      1.000000  \n",
      "2                              46      1.000000  \n",
      "3                            4793      1.000000  \n",
      "4                            1565      1.952381  \n",
      "...                           ...           ...  \n",
      "19608                          78      1.833333  \n",
      "19609                          32      1.571429  \n",
      "19610                        3817      1.315000  \n",
      "19611                       37959      1.485415  \n",
      "19612                        1667      1.958525  \n",
      "\n",
      "[19613 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the function to calculate metrics and merge with items_meta\n",
    "result = create_source_matrix(train_interactions, users_meta, items_meta)\n",
    "result.fillna(0, inplace=True)\n",
    "# Display the result DataFrame (or save it)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:51:54.529657Z",
     "iopub.status.busy": "2024-11-01T17:51:54.529225Z",
     "iopub.status.idle": "2024-11-01T17:51:54.536578Z",
     "shell.execute_reply": "2024-11-01T17:51:54.535085Z",
     "shell.execute_reply.started": "2024-11-01T17:51:54.529605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming item_metrics, result, and items_meta are already defined DataFrames.\n",
    "\n",
    "def merge_item_metrics_with_result(item_metrics, result, items_meta):\n",
    "    # Step 1: Merge item_metrics with items_meta to get source_id\n",
    "    merged_df = item_metrics.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "    \n",
    "    # Step 2: Merge the result DataFrame with the merged DataFrame on source_id\n",
    "    final_df = merged_df.merge(result, on='source_id', how='left')\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Example usage:\n",
    "# item_metrics = pd.DataFrame(...)  # Your item metrics DataFrame\n",
    "# result = pd.DataFrame(...)         # Your result DataFrame\n",
    "# items_meta = pd.DataFrame(...)     # Your items_meta DataFrame\n",
    "\n",
    "# final_merged_result = merge_item_metrics_with_result(item_metrics, result, items_meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:01:43.787438Z",
     "iopub.status.busy": "2024-11-01T18:01:43.786870Z",
     "iopub.status.idle": "2024-11-01T18:03:30.025049Z",
     "shell.execute_reply": "2024-11-01T18:03:30.023867Z",
     "shell.execute_reply.started": "2024-11-01T18:01:43.787395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loop through each specified row count\n",
    "# Calculate item metrics\n",
    "item_metrics = calculate_item_metrics(train_interactions)\n",
    "male_likes, female_likes, male_dislikes, female_dislikes = calculate_gender_metrics(train_interactions, users_meta)\n",
    "\n",
    "# Merge gender metrics\n",
    "item_metrics = item_metrics.merge(male_likes, on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(female_likes, on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(male_dislikes, on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(female_dislikes, on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(result, on='source_id', how='left')\n",
    "item_metrics = item_metrics.drop(columns=['source_id'])\n",
    "# Add suffix to distinguish metrics by row count\n",
    "\n",
    "item_metrics.columns = [f'{col}_all' if col != 'item_id' else 'item_id' for col in item_metrics.columns]\n",
    "\n",
    "# Merge into the final aggregated metrics DataFrame\n",
    "if item_metrics_final.empty:\n",
    "    item_metrics_final = item_metrics\n",
    "else:\n",
    "    item_metrics_final = item_metrics_final.merge(item_metrics, on='item_id', how='outer')\n",
    "\n",
    "# Calculate unique source counts for users and merge into user metrics DataFrame\n",
    "user_unique_sources = calculate_unique_sources(train_interactions)\n",
    "\n",
    "# Add suffix for user metrics by row count\n",
    "user_unique_sources.columns = ['user_id', f'unique_source_count_all']\n",
    "\n",
    "if user_metrics_final.empty:\n",
    "    user_metrics_final = user_unique_sources\n",
    "else:\n",
    "    user_metrics_final = user_metrics_final.merge(user_unique_sources, on='user_id', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:03:30.027165Z",
     "iopub.status.busy": "2024-11-01T18:03:30.026752Z",
     "iopub.status.idle": "2024-11-01T18:03:30.115933Z",
     "shell.execute_reply": "2024-11-01T18:03:30.114725Z",
     "shell.execute_reply.started": "2024-11-01T18:03:30.027124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "items_meta = items_meta.merge(item_metrics_final, on='item_id', how='left')\n",
    "items_meta.fillna(0, inplace=True)\n",
    "\n",
    "users_meta = users_meta.merge(user_metrics_final, on='user_id', how='left')\n",
    "users_meta.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:03:30.117969Z",
     "iopub.status.busy": "2024-11-01T18:03:30.117470Z",
     "iopub.status.idle": "2024-11-01T18:03:30.860726Z",
     "shell.execute_reply": "2024-11-01T18:03:30.859734Z",
     "shell.execute_reply.started": "2024-11-01T18:03:30.117909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_pairs = pd.read_csv('data/test_pairs.csv')\n",
    "\n",
    "users = test_pairs['user_id'].unique()\n",
    "items = test_pairs['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:03:30.862641Z",
     "iopub.status.busy": "2024-11-01T18:03:30.862193Z",
     "iopub.status.idle": "2024-11-01T18:03:32.119197Z",
     "shell.execute_reply": "2024-11-01T18:03:32.118219Z",
     "shell.execute_reply.started": "2024-11-01T18:03:30.862573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_interactions['like'] = train_interactions['like'].astype('int32')    # Convert to signed integer\n",
    "train_interactions['dislike'] = train_interactions['dislike'].astype('int32')  # Convert to signed integer\n",
    "\n",
    "train_interactions['label'] = abs(train_interactions['like'] - train_interactions['dislike'])\n",
    "\n",
    "#train_interactions = train_interactions[train_interactions['user_id'].isin(users)][train_interactions['item_id'].isin(items)]\n",
    "train_interactions = train_interactions.loc[13_000_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:03:32.121163Z",
     "iopub.status.busy": "2024-11-01T18:03:32.120665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_interactions = train_interactions.merge(users_meta, on='user_id', how='left')\n",
    "train_interactions = train_interactions.merge(items_meta, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'item_id', 'timespent', 'like', 'dislike', 'share',\n",
       "       'bookmarks', 'label', 'gender', 'age', 'unique_source_count_all',\n",
       "       'source_id', 'duration', 'total_likes_all', 'total_dislikes_all',\n",
       "       'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n",
       "       'male_likes_all', 'female_likes_all', 'male_dislikes_all',\n",
       "       'female_dislikes_all', 'total_likes_all_video_all',\n",
       "       'total_dislikes_all_video_all', 'total_encounters_all_video_all',\n",
       "       'gender_ratio_all'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_interactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T13:32:13.138628Z",
     "iopub.status.busy": "2024-11-01T13:32:13.138107Z",
     "iopub.status.idle": "2024-11-01T13:32:20.771447Z",
     "shell.execute_reply": "2024-11-01T13:32:20.769994Z",
     "shell.execute_reply.started": "2024-11-01T13:32:13.138570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_interactions = train_interactions[['gender', 'age', 'unique_source_count_all',\n",
    "       'source_id', 'duration', 'total_likes_all', 'total_dislikes_all',\n",
    "       'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n",
    "       'male_likes_all', 'female_likes_all', 'total_likes_all_video_all',\n",
    "       'total_dislikes_all_video_all', 'total_encounters_all_video_all',\n",
    "       'gender_ratio_all','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T13:32:20.774388Z",
     "iopub.status.busy": "2024-11-01T13:32:20.773726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "num_boost_round = 20\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators=num_boost_round, scale_pos_weight=11.839, **params)\n",
    "clf.fit(train_interactions.drop(columns=['label']), train_interactions['label'], \n",
    "        verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_pairs = pd.read_csv('data/test_pairs.csv')\n",
    "\n",
    "test_pairs = test_pairs.merge(users_meta, on='user_id', how='left')\n",
    "test_pairs = test_pairs.merge(items_meta, on='item_id', how='left')\n",
    "\n",
    "test_pairs = test_pairs[['gender', 'age', 'unique_source_count_all',\n",
    "       'source_id', 'duration', 'total_likes_all', 'total_dislikes_all',\n",
    "       'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n",
    "       'male_likes_all', 'female_likes_all', 'total_likes_all_video_all',\n",
    "       'total_dislikes_all_video_all', 'total_encounters_all_video_all',\n",
    "       'gender_ratio_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result = clf.predict_proba(test_pairs)\n",
    "result = [i[1] for i in result]\n",
    "\n",
    "test_pairs = pd.read_csv('data/test_pairs.csv')\n",
    "test_pairs['predict'] = result\n",
    "\n",
    "test_pairs.to_csv('sub_lightgbm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5981185,
     "sourceId": 9766180,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "vk_recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
