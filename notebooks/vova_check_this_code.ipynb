{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:40:43.644534Z",
     "iopub.status.busy": "2024-11-02T09:40:43.644091Z",
     "iopub.status.idle": "2024-11-02T09:40:47.244901Z",
     "shell.execute_reply": "2024-11-02T09:40:47.243521Z",
     "shell.execute_reply.started": "2024-11-02T09:40:43.644494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:40:47.261691Z",
     "iopub.status.busy": "2024-11-02T09:40:47.261257Z",
     "iopub.status.idle": "2024-11-02T09:40:54.498005Z",
     "shell.execute_reply": "2024-11-02T09:40:54.496686Z",
     "shell.execute_reply.started": "2024-11-02T09:40:47.261649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_interactions = pd.read_parquet('train_interactions.parquet')\n",
    "users_meta = pd.read_parquet('users_meta.parquet')\n",
    "items_meta = pd.read_parquet('items_meta.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:40:54.500671Z",
     "iopub.status.busy": "2024-11-02T09:40:54.500228Z",
     "iopub.status.idle": "2024-11-02T09:40:54.542482Z",
     "shell.execute_reply": "2024-11-02T09:40:54.541224Z",
     "shell.execute_reply.started": "2024-11-02T09:40:54.500628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "items_meta=items_meta.drop(columns=['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:40:54.544192Z",
     "iopub.status.busy": "2024-11-02T09:40:54.543831Z",
     "iopub.status.idle": "2024-11-02T09:40:54.551783Z",
     "shell.execute_reply": "2024-11-02T09:40:54.550016Z",
     "shell.execute_reply.started": "2024-11-02T09:40:54.544156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_unique_sources(df):\n",
    "    \"\"\" Calculates the number of unique source_ids for each user_id in the given DataFrame. \"\"\"\n",
    "    user_sources = df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "    unique_source_count = user_sources.groupby('user_id')['source_id'].nunique().reset_index(name='unique_source_count')\n",
    "    return unique_source_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:40:54.554145Z",
     "iopub.status.busy": "2024-11-02T09:40:54.553643Z",
     "iopub.status.idle": "2024-11-02T09:40:54.568296Z",
     "shell.execute_reply": "2024-11-02T09:40:54.567081Z",
     "shell.execute_reply.started": "2024-11-02T09:40:54.554092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare DataFrames for storing item metrics and user metrics\n",
    "item_metrics_final = pd.DataFrame()\n",
    "user_metrics_final = pd.DataFrame()\n",
    "\n",
    "# Define functions for metrics calculations\n",
    "def calculate_item_metrics(df):\n",
    "    item_metrics = df.groupby('item_id').agg(\n",
    "        total_likes=('like', 'sum'),\n",
    "        total_dislikes=('dislike', 'sum'),\n",
    "        total_shares=('share', 'sum'),\n",
    "        total_bookmarks=('bookmarks', 'sum'),\n",
    "        avg_timespent=('timespent', 'mean'),\n",
    "    ).reset_index()\n",
    "    return item_metrics\n",
    "\n",
    "def calculate_gender_metrics(df, users_meta):\n",
    "    # Merge interactions with user metadata\n",
    "    extended_df = df.merge(users_meta, on='user_id', how='left')\n",
    "\n",
    "    # Calculate likes and dislikes for males (1) and females (2)\n",
    "    gender_likes = extended_df[extended_df['like'] == 1].groupby(['item_id', 'gender']).size().unstack(fill_value=0)\n",
    "    \n",
    "    female_likes = gender_likes.get(2, pd.Series(0)).reset_index(name='female_likes')\n",
    "\n",
    "\n",
    "    # Merge the results\n",
    "    female_likes = female_likes.rename(columns={female_likes.columns[0]: 'item_id'})\n",
    "\n",
    "    return female_likes\n",
    "\n",
    "def calculate_unique_sources(df):\n",
    "    user_sources = df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "    unique_source_count = user_sources.groupby('user_id')['source_id'].nunique().reset_index(name='unique_source_count')\n",
    "    return unique_source_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:40:56.523022Z",
     "iopub.status.busy": "2024-11-02T09:40:56.522553Z",
     "iopub.status.idle": "2024-11-02T09:40:56.534260Z",
     "shell.execute_reply": "2024-11-02T09:40:56.532912Z",
     "shell.execute_reply.started": "2024-11-02T09:40:56.522977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_source_matrix(train_interactions, users_meta, items_meta):\n",
    "    extended_df = train_interactions.merge(users_meta, on='user_id', how='left')\n",
    "\n",
    "    # Step 2: Merge with items_meta to get source_id\n",
    "    extended_df = extended_df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "    # Step 3: Calculate total likes and encounters by source_id\n",
    "    likes_count = extended_df[extended_df['like'] == 1] \\\n",
    "        .groupby('source_id')['item_id'] \\\n",
    "        .count() \\\n",
    "        .reset_index(name='total_likes_all_video')\n",
    "\n",
    "    dislikes_count = extended_df[extended_df['dislike'] == 1] \\\n",
    "        .groupby('source_id')['item_id'] \\\n",
    "        .count() \\\n",
    "        .reset_index(name='total_dislikes_all_video')\n",
    "    # Step 4: Calculate gender sums who liked each source's items\n",
    "    gender_sum = extended_df[extended_df['like'] == 1] \\\n",
    "        .groupby('source_id')['gender'] \\\n",
    "        .sum() \\\n",
    "        .reset_index(name='liked_gender_sum_all_video')\n",
    "\n",
    "    encounters_count = extended_df \\\n",
    "        .groupby('source_id')['item_id'] \\\n",
    "        .count() \\\n",
    "        .reset_index(name='total_encounters_all_video')\n",
    "\n",
    "    # Step 5: Merge all metrics into a final DataFrame\n",
    "    result_matrix = likes_count \\\n",
    "        .merge(dislikes_count, on='source_id', how='outer') \\\n",
    "        .merge(encounters_count, on='source_id', how='outer') \\\n",
    "        .merge(gender_sum, on='source_id', how='outer')\n",
    "   \n",
    "    # Step 6: Calculate the gender ratio\n",
    "    result_matrix['gender_ratio'] = result_matrix['liked_gender_sum_all_video'].fillna(0) / (result_matrix['total_likes_all_video']).replace(0, pd.NA)\n",
    "    # Fill NaN values for likes and encounters\n",
    "    result_matrix=result_matrix.drop(columns=['liked_gender_sum_all_video'])\n",
    "    result_matrix.fillna(0, inplace=True)\n",
    "    return result_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:41:00.655578Z",
     "iopub.status.busy": "2024-11-02T09:41:00.655111Z",
     "iopub.status.idle": "2024-11-02T09:41:51.228935Z",
     "shell.execute_reply": "2024-11-02T09:41:51.227502Z",
     "shell.execute_reply.started": "2024-11-02T09:41:00.655516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Call the function to calculate metrics and merge with items_meta\n",
    "result = create_source_matrix(train_interactions, users_meta, items_meta)\n",
    "\n",
    "\n",
    "# Assuming item_metrics, result, and items_meta are already defined DataFrames.\n",
    "\n",
    "def merge_item_metrics_with_result(item_metrics, result, items_meta):\n",
    "    # Step 1: Merge item_metrics with items_meta to get source_id\n",
    "    merged_df = item_metrics.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "    \n",
    "    # Step 2: Merge the result DataFrame with the merged DataFrame on source_id\n",
    "    final_df = merged_df.merge(result, on='source_id', how='left')\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:41:51.231973Z",
     "iopub.status.busy": "2024-11-02T09:41:51.231452Z",
     "iopub.status.idle": "2024-11-02T09:44:13.662017Z",
     "shell.execute_reply": "2024-11-02T09:44:13.660057Z",
     "shell.execute_reply.started": "2024-11-02T09:41:51.231917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loop through each specified row count\n",
    "# Calculate item metrics\n",
    "item_metrics = calculate_item_metrics(train_interactions)\n",
    "female_likes = calculate_gender_metrics(train_interactions, users_meta)\n",
    "\n",
    "# Merge gender metrics\n",
    "item_metrics = item_metrics.merge(female_likes, on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(result, on='source_id', how='left')\n",
    "item_metrics = item_metrics.drop(columns=['source_id'])\n",
    "# Add suffix to distinguish metrics by row count\n",
    "\n",
    "item_metrics.columns = [f'{col}_all' if col != 'item_id' else 'item_id' for col in item_metrics.columns]\n",
    "\n",
    "# Merge into the final aggregated metrics DataFrame\n",
    "if item_metrics_final.empty:\n",
    "    item_metrics_final = item_metrics\n",
    "else:\n",
    "    item_metrics_final = item_metrics_final.merge(item_metrics, on='item_id', how='outer')\n",
    "\n",
    "# Calculate unique source counts for users and merge into user metrics DataFrame\n",
    "user_unique_sources = calculate_unique_sources(train_interactions)\n",
    "\n",
    "# Add suffix for user metrics by row count\n",
    "user_unique_sources.columns = ['user_id', f'unique_source_count_all']\n",
    "\n",
    "if user_metrics_final.empty:\n",
    "    user_metrics_final = user_unique_sources\n",
    "else:\n",
    "    user_metrics_final = user_metrics_final.merge(user_unique_sources, on='user_id', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:44:13.666911Z",
     "iopub.status.busy": "2024-11-02T09:44:13.665720Z",
     "iopub.status.idle": "2024-11-02T09:44:13.733519Z",
     "shell.execute_reply": "2024-11-02T09:44:13.732246Z",
     "shell.execute_reply.started": "2024-11-02T09:44:13.666847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "items_meta = items_meta.merge(item_metrics_final, on='item_id', how='left')\n",
    "items_meta.fillna(0, inplace=True)\n",
    "\n",
    "users_meta = users_meta.merge(user_metrics_final, on='user_id', how='left')\n",
    "users_meta.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:44:13.737227Z",
     "iopub.status.busy": "2024-11-02T09:44:13.736768Z",
     "iopub.status.idle": "2024-11-02T09:44:14.261814Z",
     "shell.execute_reply": "2024-11-02T09:44:14.260304Z",
     "shell.execute_reply.started": "2024-11-02T09:44:13.737178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_pairs = pd.read_csv('test_pairs.csv')\n",
    "\n",
    "users = test_pairs['user_id'].unique()\n",
    "items = test_pairs['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:44:14.263616Z",
     "iopub.status.busy": "2024-11-02T09:44:14.263182Z",
     "iopub.status.idle": "2024-11-02T09:44:15.640504Z",
     "shell.execute_reply": "2024-11-02T09:44:15.638740Z",
     "shell.execute_reply.started": "2024-11-02T09:44:14.263564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_interactions['like'] = train_interactions['like'].astype('int32')    # Convert to signed integer\n",
    "train_interactions['dislike'] = train_interactions['dislike'].astype('int32')  # Convert to signed integer\n",
    "\n",
    "train_interactions['label'] = abs(train_interactions['like'] - train_interactions['dislike'])\n",
    "\n",
    "#train_interactions = train_interactions[train_interactions['user_id'].isin(users)][train_interactions['item_id'].isin(items)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:44:15.642620Z",
     "iopub.status.busy": "2024-11-02T09:44:15.642173Z",
     "iopub.status.idle": "2024-11-02T09:45:20.732529Z",
     "shell.execute_reply": "2024-11-02T09:45:20.730951Z",
     "shell.execute_reply.started": "2024-11-02T09:44:15.642569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_interactions = train_interactions.merge(users_meta, on='user_id', how='left')\n",
    "train_interactions = train_interactions.merge(items_meta, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:45:33.017468Z",
     "iopub.status.busy": "2024-11-02T09:45:33.016992Z",
     "iopub.status.idle": "2024-11-02T09:45:33.027531Z",
     "shell.execute_reply": "2024-11-02T09:45:33.026068Z",
     "shell.execute_reply.started": "2024-11-02T09:45:33.017426Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'item_id', 'timespent', 'like', 'dislike', 'share',\n",
       "       'bookmarks', 'label', 'gender', 'age', 'unique_source_count_all',\n",
       "       'source_id', 'duration', 'total_likes_all', 'total_dislikes_all',\n",
       "       'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n",
       "       'female_likes_all', 'total_likes_all_video_all',\n",
       "       'total_dislikes_all_video_all', 'total_encounters_all_video_all',\n",
       "       'gender_ratio_all'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_interactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:45:56.265896Z",
     "iopub.status.busy": "2024-11-02T09:45:56.265426Z",
     "iopub.status.idle": "2024-11-02T09:46:06.601658Z",
     "shell.execute_reply": "2024-11-02T09:46:06.600277Z",
     "shell.execute_reply.started": "2024-11-02T09:45:56.265855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_interactions = train_interactions[['gender', 'age', 'unique_source_count_all',\n",
    "       'source_id', 'duration', 'total_likes_all', 'total_dislikes_all',\n",
    "       'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n",
    "       'female_likes_all', 'total_likes_all_video_all',\n",
    "       'total_dislikes_all_video_all', 'total_encounters_all_video_all',\n",
    "       'gender_ratio_all', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train_interactions.groupby('user_id').size().to_frame('size')['size'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRanker(  \n",
    "    tree_method='hist',\n",
    "    booster='gbtree',\n",
    "    objective='rank:pairwise',\n",
    "    random_state=42, \n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=0.9, \n",
    "    eta=0.05, \n",
    "    max_depth=6, \n",
    "    n_estimators=5, \n",
    "    subsample=0.75 \n",
    ")\n",
    "\n",
    "model.fit(train_interactions.drop(columns=['user_id', 'label']), train_interactions['label'], group=groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "num_boost_round = 50\n",
    "class_weight = len(train_interactions[train_interactions['label'] == 0]) / len(train_interactions[train_interactions['label'] == 1])\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators=num_boost_round, scale_pos_weight=class_weight, **params)\n",
    "clf.fit(train_interactions.drop(columns=['label']), train_interactions['label'], \n",
    "        verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = pd.read_csv('data/test_pairs.csv')\n",
    "\n",
    "test_pairs = test_pairs.merge(users_meta, on='user_id', how='left')\n",
    "test_pairs = test_pairs.merge(items_meta, on='item_id', how='left')\n",
    "\n",
    "test_pairs = test_pairs[['gender', 'age', 'unique_source_count_all',\n",
    "       'source_id', 'duration', 'total_likes_all', 'total_dislikes_all',\n",
    "       'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n",
    "       'female_likes_all', 'total_likes_all_video_all',\n",
    "       'total_dislikes_all_video_all', 'total_encounters_all_video_all',\n",
    "       'gender_ratio_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, df):\n",
    "    return model.predict(df.loc[:, ~df.columns.isin(['user_id'])])\n",
    "  \n",
    "predictions = (test_pairs.groupby('user_id')\n",
    "               .apply(lambda x: predict(model, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.predict_proba(test_pairs)\n",
    "result = [i[1] for i in result]\n",
    "\n",
    "test_pairs = pd.read_csv('test_pairs.csv')\n",
    "test_pairs['predict'] = result\n",
    "\n",
    "test_pairs.to_csv('max_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5981185,
     "sourceId": 9766180,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5995930,
     "sourceId": 9786062,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
