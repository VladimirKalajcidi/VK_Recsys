{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /Users/vladimirkalajcidi/vk_recsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_interactions = pd.read_parquet('data/train_interactions.parquet')\n",
    "users_meta = pd.read_parquet('data/users_meta.parquet')\n",
    "items_meta = pd.read_parquet('data/items_meta.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_unique_sources(df):\n",
    "    \"\"\" Calculates the number of unique source_ids for each user_id in the given DataFrame. \"\"\"\n",
    "    user_sources = df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "    unique_source_count = user_sources.groupby('user_id')['source_id'].nunique().reset_index(name='unique_source_count')\n",
    "    return unique_source_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define row counts\n",
    "row_counts = [5_000_000, 10_000_000, 50_000_000]\n",
    "\n",
    "# Prepare DataFrames for storing item metrics and user metrics\n",
    "item_metrics_final = pd.DataFrame()\n",
    "user_metrics_final = pd.DataFrame()\n",
    "\n",
    "# Define functions for metrics calculations\n",
    "def calculate_item_metrics(df):\n",
    "    item_metrics = df.groupby('item_id').agg(\n",
    "        total_likes=('like', 'sum'),\n",
    "        total_dislikes=('dislike', 'sum'),\n",
    "        total_shares=('share', 'sum'),\n",
    "        total_bookmarks=('bookmarks', 'sum'),\n",
    "        avg_timespent=('timespent', 'mean'),\n",
    "    ).reset_index()\n",
    "    return item_metrics\n",
    "\n",
    "def calculate_gender_metrics(df, users_meta):\n",
    "    # Merge interactions with user metadata\n",
    "    extended_df = df.merge(users_meta, on='user_id', how='left')\n",
    "\n",
    "    # Calculate likes and dislikes for males (1) and females (2)\n",
    "    gender_likes = extended_df[extended_df['like'] == 1].groupby(['item_id', 'gender']).size().unstack(fill_value=0)\n",
    "\n",
    "    male_likes = gender_likes.get(1, pd.Series(0)).reset_index(name='male_likes')\n",
    "    female_likes = gender_likes.get(2, pd.Series(0)).reset_index(name='female_likes')\n",
    "\n",
    "    gender_dislikes = extended_df[extended_df['dislike'] == 1].groupby(['item_id', 'gender']).size().unstack(fill_value=0)\n",
    "\n",
    "    male_dislikes = gender_dislikes.get(1, pd.Series(0)).reset_index(name='male_dislikes')\n",
    "    female_dislikes = gender_dislikes.get(2, pd.Series(0)).reset_index(name='female_dislikes')\n",
    "\n",
    "    # Merge the results\n",
    "    male_likes = male_likes.rename(columns={male_likes.columns[0]: 'item_id'})\n",
    "    female_likes = female_likes.rename(columns={female_likes.columns[0]: 'item_id'})\n",
    "    male_dislikes = male_dislikes.rename(columns={male_dislikes.columns[0]: 'item_id'})\n",
    "    female_dislikes = female_dislikes.rename(columns={female_dislikes.columns[0]: 'item_id'})\n",
    "\n",
    "    return male_likes, female_likes, male_dislikes, female_dislikes\n",
    "\n",
    "def calculate_unique_sources(df):\n",
    "    user_sources = df.merge(items_meta[['item_id', 'source_id']], on='item_id', how='left')\n",
    "    unique_source_count = user_sources.groupby('user_id')['source_id'].nunique().reset_index(name='unique_source_count')\n",
    "    return unique_source_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loop through each specified row count\n",
    "for count in row_counts:\n",
    "    if count == len(train_interactions):\n",
    "        df_sample = train_interactions\n",
    "    else:\n",
    "        df_sample = train_interactions.tail(count)\n",
    "\n",
    "    # Calculate item metrics\n",
    "    item_metrics = calculate_item_metrics(df_sample)\n",
    "    male_likes, female_likes, male_dislikes, female_dislikes = calculate_gender_metrics(df_sample, users_meta)\n",
    "\n",
    "    # Merge gender metrics\n",
    "    item_metrics = item_metrics.merge(male_likes, on='item_id', how='left')\n",
    "    item_metrics = item_metrics.merge(female_likes, on='item_id', how='left')\n",
    "    item_metrics = item_metrics.merge(male_dislikes, on='item_id', how='left')\n",
    "    item_metrics = item_metrics.merge(female_dislikes, on='item_id', how='left')\n",
    "\n",
    "    # Add suffix to distinguish metrics by row count\n",
    "    suffix = f'_{count}'\n",
    "    item_metrics.columns = [f'{col}{suffix}' if col != 'item_id' else 'item_id' for col in item_metrics.columns]\n",
    "\n",
    "    # Merge into the final aggregated metrics DataFrame\n",
    "    if item_metrics_final.empty:\n",
    "        item_metrics_final = item_metrics\n",
    "    else:\n",
    "        item_metrics_final = item_metrics_final.merge(item_metrics, on='item_id', how='outer')\n",
    "\n",
    "    # Calculate unique source counts for users and merge into user metrics DataFrame\n",
    "    user_unique_sources = calculate_unique_sources(df_sample)\n",
    "\n",
    "    # Add suffix for user metrics by row count\n",
    "    user_unique_sources.columns = ['user_id', f'unique_source_count{suffix}']\n",
    "\n",
    "    if user_metrics_final.empty:\n",
    "        user_metrics_final = user_unique_sources\n",
    "    else:\n",
    "        user_metrics_final = user_metrics_final.merge(user_unique_sources, on='user_id', how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through each specified row count\n",
    "# Calculate item metrics\n",
    "item_metrics = calculate_item_metrics(train_interactions)\n",
    "male_likes, female_likes, male_dislikes, female_dislikes = calculate_gender_metrics(train_interactions, users_meta)\n",
    "\n",
    "# Merge gender metrics\n",
    "item_metrics = item_metrics.merge(male_likes, on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(female_likes, on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(male_dislikes, on='item_id', how='left')\n",
    "item_metrics = item_metrics.merge(female_dislikes, on='item_id', how='left')\n",
    "\n",
    "# Add suffix to distinguish metrics by row count\n",
    "\n",
    "item_metrics.columns = [f'{col}_all' if col != 'item_id' else 'item_id' for col in item_metrics.columns]\n",
    "\n",
    "# Merge into the final aggregated metrics DataFrame\n",
    "if item_metrics_final.empty:\n",
    "    item_metrics_final = item_metrics\n",
    "else:\n",
    "    item_metrics_final = item_metrics_final.merge(item_metrics, on='item_id', how='outer')\n",
    "\n",
    "# Calculate unique source counts for users and merge into user metrics DataFrame\n",
    "user_unique_sources = calculate_unique_sources(train_interactions)\n",
    "\n",
    "# Add suffix for user metrics by row count\n",
    "user_unique_sources.columns = ['user_id', f'unique_source_count_all']\n",
    "\n",
    "if user_metrics_final.empty:\n",
    "    user_metrics_final = user_unique_sources\n",
    "else:\n",
    "    user_metrics_final = user_metrics_final.merge(user_unique_sources, on='user_id', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "items_meta = items_meta.merge(item_metrics_final, on='item_id', how='left')\n",
    "items_meta.fillna(0, inplace=True)\n",
    "\n",
    "users_meta = users_meta.merge(user_metrics_final, on='user_id', how='left')\n",
    "users_meta.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_pairs = pd.read_csv('data/test_pairs.csv')\n",
    "\n",
    "users = test_pairs['user_id'].unique()\n",
    "items = test_pairs['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_interactions['like'] = train_interactions['like'].astype('int32')    # Convert to signed integer\n",
    "train_interactions['dislike'] = train_interactions['dislike'].astype('int32')  # Convert to signed integer\n",
    "\n",
    "# Now create the 'weight' column\n",
    "train_interactions['label'] = train_interactions['like'] - train_interactions['dislike']\n",
    "\n",
    "train_interactions = train_interactions[train_interactions['user_id'].isin(users)][train_interactions['item_id'].isin(items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_interactions = train_interactions.merge(users_meta, on='user_id', how='left')\n",
    "train_interactions = train_interactions.merge(items_meta, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "new_mapping = {\n",
    "    1: 1,      # Change to 1\n",
    "    0: 0,    # Change to 0\n",
    "    -1: 0    # Change to 0\n",
    "}\n",
    "\n",
    "# Use replace to update the interaction column\n",
    "train_interactions['label'] = train_interactions['label'].replace(new_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_interactions = train_interactions[['gender', 'age', 'unique_source_count_all', 'source_id', 'duration', 'total_likes_all', 'total_dislikes_all',\n",
    "                            'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n",
    "                            'male_likes_all', 'female_likes_all', 'male_dislikes_all',\n",
    "                            'female_dislikes_all', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "num_boost_round = 50\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators=num_boost_round, scale_pos_weight=11.839, **params)\n",
    "clf.fit(interactions.drop(columns=['label']), interactions['label'], \n",
    "        verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_pairs = pd.read_csv('data/test_pairs.csv')\n",
    "\n",
    "test_pairs = test_pairs.merge(users_meta, on='user_id', how='left')\n",
    "test_pairs = test_pairs.merge(items_meta, on='item_id', how='left')\n",
    "\n",
    "test_pairs = test_pairs[['gender', 'age', 'unique_source_count_all', 'source_id', 'duration', 'total_likes_all', 'total_dislikes_all',\n",
    "                            'total_shares_all', 'total_bookmarks_all', 'avg_timespent_all',\n",
    "                            'male_likes_all', 'female_likes_all', 'male_dislikes_all',\n",
    "                            'female_dislikes_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result = clf.predict_proba(test_pairs)\n",
    "result = [i[1] for i in result]\n",
    "\n",
    "test_pairs = pd.read_csv('data/test_pairs.csv')\n",
    "test_pairs['predict'] = result\n",
    "\n",
    "test_pairs.to_csv('sub_lightgbm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
